{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdaeheenusconda3c7a847601004481b45b1fba19be0f67",
   "display_name": "Python 3.7.9 64-bit ('daehee_nus': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import visdom\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mtp2 import MTP, MTPLoss\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./exps/hoon17 already exsits.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "shuffle = False\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = util.DataSet_proj('./dataset_chh/' + 'train_val', 'train_val')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',       required=True,  type=str,   help='experiment name. saved to ./exps/[name]')\n",
    "parser.add_argument('--ep',         required=True,  type=str)\n",
    "args = parser.parse_args('--name hoon17 --ep best'.split(' '))\n",
    "exp_path, train_path, val_path, infer_path, ckpt_path = util.make_path(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "model = torch.load(ckpt_path + '/' + 'model.archi')\n",
    "model.load_state_dict(torch.load(ckpt_path + '/' + 'weight_' + args.ep + '.pth')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 49/49 [01:47<00:00,  2.19s/it]\n",
      " dac :  0.9605934907466485\n",
      "\n",
      " ade :  74.30407556311846\n",
      "\n",
      " fde :  193.41256296569222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "transform_dac = transforms.Compose([transforms.ToPILImage(), transforms.Resize(500), transforms.ToTensor()])\n",
    "\n",
    "loss_val_mean = []\n",
    "dac = 0.\n",
    "num_samp = 0\n",
    "ade = 0.\n",
    "fde = 0.\n",
    "for raster, road, lane, agents, state, past, gt in tqdm(dataloader):\n",
    "    raster, road, lane, agents, state, past, gt = util.NaN2Zero(raster), util.NaN2Zero(road), util.NaN2Zero(lane), util.NaN2Zero(agents), util.NaN2Zero(state), util.NaN2Zero(past),  util.NaN2Zero(gt)\n",
    "    raster, road, lane, agents, state, past, gt = raster.to(device), road.to(device), lane.to(device), agents.to(device), state.to(device), past.to(device), gt.to(device)\n",
    "\n",
    "    prediction = model(road, lane, agents, state, past)\n",
    "\n",
    "    for road_, pred_ in zip(road, prediction):\n",
    "        road_ = util.restore_img(road_.cpu())\n",
    "        road_ = transform_dac(road_).numpy()\n",
    "        road_ = (road_ * 255).astype(np.uint8)\n",
    "\n",
    "        dac_ = util.dac_metric(road_, pred_)\n",
    "        dac += dac_\n",
    "\n",
    "        gt_e = gt_.view(-1)\n",
    "        pred_e = pred_[:-1]\n",
    "\n",
    "        ade_ = ((gt_e - pred_e)**2).sum(dim=0) / len(gt_e)\n",
    "        ade += ade_.item()\n",
    "\n",
    "        fde_ = ((gt_e[-2:] - pred_e[-2:])**2).sum(dim=0) / 2\n",
    "        fde += fde_.item()\n",
    "\n",
    "        num_samp += 1\n",
    "\n",
    "print('\\n', 'dac : ', dac/num_samp)\n",
    "print('\\n', 'ade : ', ade/num_samp)\n",
    "print('\\n', 'fde : ', fde/num_samp)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "ckpt_path = './exps/1130_mode1/ckpt'\n",
    "ep = 'best'\n",
    "\n",
    "model = torch.load(ckpt_path + '/' + 'model.archi')\n",
    "model.load_state_dict(torch.load(ckpt_path + '/' + 'weight_' + ep + '.pth')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 49/49 [01:23<00:00,  1.71s/it]\n",
      " dac :  0.952111252924909\n",
      "\n",
      " ade :  23.13349279402812\n",
      "\n",
      " fde :  82.25350927679288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "transform_dac = transforms.Compose([transforms.ToPILImage(), transforms.Resize(500), transforms.ToTensor()])\n",
    "\n",
    "loss_val_mean = []\n",
    "dac = 0.\n",
    "num_samp = 0\n",
    "ade = 0.\n",
    "fde = 0.\n",
    "for raster, road, lane, agents, state, past, gt in tqdm(dataloader):\n",
    "    raster, road, lane, agents, state, past, gt = util.NaN2Zero(raster), util.NaN2Zero(road), util.NaN2Zero(lane), util.NaN2Zero(agents), util.NaN2Zero(state), util.NaN2Zero(past),  util.NaN2Zero(gt)\n",
    "    raster, road, lane, agents, state, past, gt = raster.to(device), road.to(device), lane.to(device), agents.to(device), state.to(device), past.to(device), gt.to(device)\n",
    "\n",
    "    prediction = model(raster, state)\n",
    "\n",
    "    for road_, pred_, gt_ in zip(road, prediction, gt):\n",
    "        road_ = util.restore_img(road_.cpu())\n",
    "        road_ = transform_dac(road_).numpy()\n",
    "        road_ = (road_ * 255).astype(np.uint8)\n",
    "\n",
    "        gt_e = gt_.view(-1)\n",
    "        pred_e = pred_[:-1]\n",
    "\n",
    "        ade_ = ((gt_e - pred_e)**2).sum(dim=0) / len(gt_e)\n",
    "        ade += ade_.item()\n",
    "\n",
    "        fde_ = ((gt_e[-2:] - pred_e[-2:])**2).sum(dim=0) / 2\n",
    "        fde += fde_.item()\n",
    "\n",
    "        dac_ = util.dac_metric(road_, pred_)\n",
    "        dac += dac_\n",
    "        num_samp += 1\n",
    "\n",
    "print('\\n', 'dac : ', dac/num_samp)\n",
    "print('\\n', 'ade : ', ade/num_samp)\n",
    "print('\\n', 'fde : ', fde/num_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22.403121948242188"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "fde_.item()"
   ]
  }
 ]
}