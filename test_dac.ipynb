{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdaeheenusconda3c7a847601004481b45b1fba19be0f67",
   "display_name": "Python 3.7.9 64-bit ('daehee_nus': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import visdom\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mtp2 import MTP, MTPLoss\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./exps/hoon17 already exsits.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "shuffle = False\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = util.DataSet_proj('./data_chh/' + 'train_val', 'train_val')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',       required=True,  type=str,   help='experiment name. saved to ./exps/[name]')\n",
    "parser.add_argument('--ep',         required=True,  type=str)\n",
    "args = parser.parse_args('--name hoon17 --ep best'.split(' '))\n",
    "exp_path, train_path, val_path, infer_path, ckpt_path = util.make_path(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model = torch.load(ckpt_path + '/' + 'model.archi')\n",
    "model.load_state_dict(torch.load(ckpt_path + '/' + 'weight_' + args.ep + '.pth')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 49/49 [00:53<00:00,  1.10s/it]\n",
      " dac :  0.9605934907466485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "transform_dac = transforms.Compose([transforms.ToPILImage(), transforms.Resize(500), transforms.ToTensor()])\n",
    "\n",
    "loss_val_mean = []\n",
    "dac = 0.\n",
    "num_samp = 0\n",
    "for road, lane, agents, state, past, gt in tqdm(dataloader):\n",
    "    road, lane, agents, state, past, gt = util.NaN2Zero(road), util.NaN2Zero(lane), util.NaN2Zero(agents), util.NaN2Zero(state), util.NaN2Zero(past),  util.NaN2Zero(gt)\n",
    "    road, lane, agents, state, past, gt = road.to(device), lane.to(device), agents.to(device), state.to(device), past.to(device), gt.to(device)\n",
    "\n",
    "    prediction = model(road, lane, agents, state, past)\n",
    "\n",
    "    for road_, pred_ in zip(road, prediction):\n",
    "        road_ = util.restore_img(road_.cpu())\n",
    "        road_ = transform_dac(road_).numpy()\n",
    "        road_ = (road_ * 255).astype(np.uint8)\n",
    "        dac_ = util.dac_metric(road_, pred_)\n",
    "        dac += dac_\n",
    "        num_samp += 1\n",
    "\n",
    "print('\\n', 'dac : ', dac/num_samp)\n",
    "\n",
    "\n"
   ]
  }
 ]
}