{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdaeheenusconda3c7a847601004481b45b1fba19be0f67",
   "display_name": "Python 3.7.9 64-bit ('daehee_nus': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from backbone import ResNetBackbone, MobileNetBackbone\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import visdom\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mtp import MTP, MTP_baseline, MTPLoss\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--ep'], dest='ep', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help=None, metavar=None)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "batch_size = 8\n",
    "num_workers = 8\n",
    "shuffle = False\n",
    "is_diff = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = util.DataSet_proj('./dataset_chh/' + 'train_val', 'train_val')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',       required=True,  type=str,   help='experiment name. saved to ./exps/[name]')\n",
    "parser.add_argument('--ep',         required=True,  type=str)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./exps/1130_mode1_152_att_1 already exsits.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\n",
    "args = parser.parse_args('--name 1130_mode1_152_att_1 --ep best'.split(' '))\n",
    "exp_path, train_path, val_path, infer_path, ckpt_path = util.make_path(args)\n",
    "# model = torch.load(ckpt_path + '/' + 'model.archi')\n",
    "model = MTP(backbone=ResNetBackbone('resnet152'))\n",
    "model.load_state_dict(torch.load(ckpt_path + '/' + 'weight_' + args.ep + '.pth')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 392/392 [01:37<00:00,  4.01it/s]\n",
      " dac :  0.9649276749627735\n",
      "\n",
      " ade :  19.174236933420808\n",
      "\n",
      " fde :  70.30943596842414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "transform_dac = transforms.Compose([transforms.ToPILImage(), transforms.Resize(500), transforms.ToTensor()])\n",
    "\n",
    "loss_val_mean = []\n",
    "dac = 0.\n",
    "num_samp = 0\n",
    "ade = 0.\n",
    "fde = 0.\n",
    "for raster, road, lane, agents, state, past, gt in tqdm(dataloader):\n",
    "    raster, road, lane, agents, state, past, gt = util.NaN2Zero(raster), util.NaN2Zero(road), util.NaN2Zero(lane), util.NaN2Zero(agents), util.NaN2Zero(state), util.NaN2Zero(past),  util.NaN2Zero(gt)\n",
    "    raster, road, lane, agents, state, past, gt = raster.to(device), road.to(device), lane.to(device), agents.to(device), state.to(device), past.to(device), gt.to(device)\n",
    "\n",
    "    prediction = model(road, lane, agents, state, past)\n",
    "\n",
    "    for road_, pred_, gt_ in zip(road, prediction, gt):\n",
    "        road_ = util.restore_img(road_.cpu())\n",
    "        road_ = transform_dac(road_).numpy()\n",
    "        road_ = (road_ * 255).astype(np.uint8)\n",
    "\n",
    "        dac_ = util.dac_metric(road_, pred_)\n",
    "        dac += dac_\n",
    "\n",
    "        gt_e = gt_.view(-1)\n",
    "        pred_e = pred_[:-1]\n",
    "\n",
    "        ade_ = ((gt_e - pred_e)**2).sum(dim=0) / len(gt_e)\n",
    "        ade += ade_.item()\n",
    "\n",
    "        fde_ = ((gt_e[-2:] - pred_e[-2:])**2).sum(dim=0) / 2\n",
    "        fde += fde_.item()\n",
    "\n",
    "        num_samp += 1\n",
    "\n",
    "print('\\n', 'dac : ', dac/num_samp)\n",
    "print('\\n', 'ade : ', ade/num_samp)\n",
    "print('\\n', 'fde : ', fde/num_samp)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Difference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = 'exps/1201_mode1_mbnet_diff_1'\n",
    "ckpt_path = exp_path + '/ckpt'\n",
    "ep = 'best'\n",
    "\n",
    "model = MTP_baseline(backbone=MobileNetBackbone('mobilenet_v2'), num_modes=1, is_diff=True)\n",
    "model.load_state_dict(torch.load(ckpt_path + '/' + 'weight_' + ep + '.pth')['state_dict'])\n",
    "\n",
    "dataset = util.DataSet_proj('./dataset_chh/' + 'train_val', 'train_val')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 392/392 [03:26<00:00,  1.90it/s]\n",
      " dac :  0.9241384811742178\n",
      "\n",
      " ade :  21.58204356461155\n",
      "\n",
      " fde :  79.69678150122152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "transform_dac = transforms.Compose([transforms.ToPILImage(), transforms.Resize(500), transforms.ToTensor()])\n",
    "\n",
    "loss_val_mean = []\n",
    "dac = 0.\n",
    "num_samp = 0\n",
    "ade = 0.\n",
    "fde = 0.\n",
    "for raster, road, lane, agents, state, past, gt, diff in tqdm(dataloader):\n",
    "    raster, road, lane, agents, state, past, gt, diff = util.NaN2Zero(raster), util.NaN2Zero(road), util.NaN2Zero(lane), util.NaN2Zero(agents), util.NaN2Zero(state), util.NaN2Zero(past),  util.NaN2Zero(gt), util.NaN2Zero(diff)\n",
    "    raster, road, state, gt, diff = raster.to(device), road.to(device), state.to(device), gt.to(device), diff.to(device)\n",
    "\n",
    "    prediction = model(raster, state)\n",
    "\n",
    "    for road_, pred_, gt_ in zip(road, prediction, gt):\n",
    "        road_ = util.restore_img(road_.cpu())\n",
    "        road_ = transform_dac(road_).numpy()\n",
    "        road_ = (road_ * 255).astype(np.uint8)\n",
    "\n",
    "        ########## convert predicted displacement to coordinate #########\n",
    "        tra_ = pred_[:-1]\n",
    "        tra_ = torch.reshape(tra_, (-1,2))\n",
    "        tra_[0] = tra_[0] + gt_[0]\n",
    "\n",
    "        for i in range(len(tra_)-1):\n",
    "            tra_[i+1] = tra_[i] + tra_[i+1]\n",
    "\n",
    "        pred_ = torch.cat((gt_[0], tra_.reshape(-1), pred_[-1:]))\n",
    "        ##################################################################\n",
    "\n",
    "        gt_e = gt_.view(-1)\n",
    "        pred_e = pred_[:-1]\n",
    "\n",
    "        ade_ = ((gt_e - pred_e)**2).sum(dim=0) / len(gt_e)\n",
    "        ade += ade_.item()\n",
    "\n",
    "        fde_ = ((gt_e[-2:] - pred_e[-2:])**2).sum(dim=0) / 2\n",
    "        fde += fde_.item()\n",
    "\n",
    "        dac_ = util.dac_metric(road_, pred_)\n",
    "        dac += dac_\n",
    "        num_samp += 1\n",
    "\n",
    "print('\\n', 'dac : ', dac/num_samp)\n",
    "print('\\n', 'ade : ', ade/num_samp)\n",
    "print('\\n', 'fde : ', fde/num_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_ = pred_[:-1]\n",
    "tra_ = torch.reshape(tra_, (-1,2))\n",
    "tra_[0] = tra_[0] + gt_[0]\n",
    "\n",
    "for i in range(len(tra_)-1):\n",
    "    tra_[i+1] = tra_[i] + tra_[i+1]\n",
    "\n",
    "pred__ = torch.cat((gt_[0], tra_.reshape(-1), pred_[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.5136e-01, 2.1945e+00, 3.9808e-01, 6.6412e+00, 8.4048e-01, 1.3486e+01,\n",
       "        1.4682e+00, 2.2763e+01, 2.3084e+00, 3.4366e+01, 3.4426e+00, 4.8137e+01,\n",
       "        4.9762e+00, 6.3944e+01, 6.9345e+00, 8.1991e+01, 9.4172e+00, 1.0246e+02,\n",
       "        1.2306e+01, 1.2553e+02, 1.5684e+01, 1.5115e+02, 1.9598e+01, 1.7934e+02,\n",
       "        1.0000e+00], device='cuda:0', grad_fn=<CatBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pred__"
   ]
  },
  {
   "source": [
    "## Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# from mtp_orig import MTP, MTPLoss\n",
    "\n",
    "\n",
    "exp_path = 'exps/1201_mode1_mbnet_1'\n",
    "ckpt_path = exp_path + '/ckpt'\n",
    "ep = 'best'\n",
    "\n",
    "# model = torch.load(ckpt_path + '/' + 'model.archi')\n",
    "# print(model)\n",
    "model = MTP_baseline(backbone=MobileNetBackbone('mobilenet_v2'), num_modes=1, is_diff=False)\n",
    "model.load_state_dict(torch.load(ckpt_path + '/' + 'weight_' + ep + '.pth')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 392/392 [03:28<00:00,  1.88it/s]\n",
      " dac :  0.943629015103169\n",
      "\n",
      " ade :  24.752807428227083\n",
      "\n",
      " fde :  82.45944582745899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "transform_dac = transforms.Compose([transforms.ToPILImage(), transforms.Resize(500), transforms.ToTensor()])\n",
    "\n",
    "loss_val_mean = []\n",
    "dac = 0.\n",
    "num_samp = 0\n",
    "ade = 0.\n",
    "fde = 0.\n",
    "for raster, road, lane, agents, state, past, gt, _ in tqdm(dataloader):\n",
    "    raster, road, lane, agents, state, past, gt = util.NaN2Zero(raster), util.NaN2Zero(road), util.NaN2Zero(lane), util.NaN2Zero(agents), util.NaN2Zero(state), util.NaN2Zero(past),  util.NaN2Zero(gt)\n",
    "    raster, road, state, gt = raster.to(device), road.to(device), state.to(device), gt.to(device)\n",
    "\n",
    "    prediction = model(raster, state)\n",
    "\n",
    "    for road_, pred_, gt_ in zip(road, prediction, gt):\n",
    "        road_ = util.restore_img(road_.cpu())\n",
    "        road_ = transform_dac(road_).numpy()\n",
    "        road_ = (road_ * 255).astype(np.uint8)\n",
    "\n",
    "        gt_e = gt_.view(-1)\n",
    "        pred_e = pred_[:-1]\n",
    "\n",
    "        ade_ = ((gt_e - pred_e)**2).sum(dim=0) / len(gt_e)\n",
    "        ade += ade_.item()\n",
    "\n",
    "        fde_ = ((gt_e[-2:] - pred_e[-2:])**2).sum(dim=0) / 2\n",
    "        fde += fde_.item()\n",
    "\n",
    "        dac_ = util.dac_metric(road_, pred_)\n",
    "        dac += dac_\n",
    "        num_samp += 1\n",
    "\n",
    "print('\\n', 'dac : ', dac/num_samp)\n",
    "print('\\n', 'ade : ', ade/num_samp)\n",
    "print('\\n', 'fde : ', fde/num_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22.403121948242188"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "fde_.item()"
   ]
  }
 ]
}